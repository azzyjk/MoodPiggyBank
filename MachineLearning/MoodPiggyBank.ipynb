{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "MoodPiggyBankLikePytorchTest.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "oT-2KuRl3cyT",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 310
        },
        "outputId": "b2f71683-1752-4c5f-e406-18b0def27ab6"
      },
      "source": [
        "!pip install konlpy\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "%matplotlib inline\n",
        "import matplotlib.pyplot as plt\n",
        "import re\n",
        "import urllib.request\n",
        "from konlpy.tag import Okt\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.optimizers import *\n",
        "from tensorflow.keras.losses import *\n",
        "from tensorflow.nn import *\n",
        "from nltk.util import ngrams\n",
        "from sklearn.model_selection import *\n",
        "from tensorflow.keras.utils import plot_model\n",
        "\n",
        "from tensorflow.keras.activations import *\n",
        "from tensorflow.keras.layers import *\n",
        "from tensorflow.keras.models import Sequential, Model\n",
        "from tensorflow.keras.models import load_model\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
        "\n",
        "urllib.request.urlretrieve(\"https://raw.githubusercontent.com/e9t/nsmc/master/ratings_train.txt\", filename=\"ratings_train.txt\")\n",
        "urllib.request.urlretrieve(\"https://raw.githubusercontent.com/e9t/nsmc/master/ratings_test.txt\", filename=\"ratings_test.txt\")\n",
        "\n"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: konlpy in /usr/local/lib/python3.6/dist-packages (0.5.2)\n",
            "Requirement already satisfied: numpy>=1.6 in /usr/local/lib/python3.6/dist-packages (from konlpy) (1.18.5)\n",
            "Requirement already satisfied: lxml>=4.1.0 in /usr/local/lib/python3.6/dist-packages (from konlpy) (4.2.6)\n",
            "Requirement already satisfied: beautifulsoup4==4.6.0 in /usr/local/lib/python3.6/dist-packages (from konlpy) (4.6.0)\n",
            "Requirement already satisfied: tweepy>=3.7.0 in /usr/local/lib/python3.6/dist-packages (from konlpy) (3.9.0)\n",
            "Requirement already satisfied: colorama in /usr/local/lib/python3.6/dist-packages (from konlpy) (0.4.3)\n",
            "Requirement already satisfied: JPype1>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from konlpy) (1.0.2)\n",
            "Requirement already satisfied: requests[socks]>=2.11.1 in /usr/local/lib/python3.6/dist-packages (from tweepy>=3.7.0->konlpy) (2.23.0)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from tweepy>=3.7.0->konlpy) (1.3.0)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from tweepy>=3.7.0->konlpy) (1.15.0)\n",
            "Requirement already satisfied: typing-extensions; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from JPype1>=0.7.0->konlpy) (3.7.4.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests[socks]>=2.11.1->tweepy>=3.7.0->konlpy) (2020.6.20)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests[socks]>=2.11.1->tweepy>=3.7.0->konlpy) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests[socks]>=2.11.1->tweepy>=3.7.0->konlpy) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests[socks]>=2.11.1->tweepy>=3.7.0->konlpy) (3.0.4)\n",
            "Requirement already satisfied: PySocks!=1.5.7,>=1.5.6; extra == \"socks\" in /usr/local/lib/python3.6/dist-packages (from requests[socks]>=2.11.1->tweepy>=3.7.0->konlpy) (1.7.1)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.6/dist-packages (from requests-oauthlib>=0.7.0->tweepy>=3.7.0->konlpy) (3.1.0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('ratings_test.txt', <http.client.HTTPMessage at 0x7f9079ad1198>)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5-hhpAxOYzMr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def preprocessing(data):\n",
        "  data = data.drop_duplicates(subset=['document'])\n",
        "  data = data.dropna(how = 'any')\n",
        "  data['document'] = data['document'].str.replace(\"[^ㄱ-ㅎㅏ-ㅣ가-힣 ]\",\"\")\n",
        "  data['document'] = data['document'].replace('', np.nan)\n",
        "  data = data.dropna(how = 'any')\n",
        "  return data"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LQ0d9S--BCtl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def Token(data, okt, stopwords):\n",
        "  now = 0\n",
        "  res = list()\n",
        "  \n",
        "  print(\"start token\")\n",
        "  for sentence in data['document']:\n",
        "    if now%10000 == 0:\n",
        "      print(f\"token : {now}/{len(data)}\")\n",
        "    now = now +1\n",
        "    temp = list()\n",
        "    for i in range(len(sentence)):\n",
        "      temp.append(sentence[i])\n",
        "    res.append(temp)\n",
        "  print(\"end token\")\n",
        "  return res"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-58IuB2LTZRI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def Tokenizing(data, tokenizer):\n",
        "  return tokenizer.texts_to_sequences(data)"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "akEbJd15nU-l",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def rmEmpty(data, label):\n",
        "  drop_data = [index for index, sentence in enumerate(X_train) if len(sentence) < 1]\n",
        "  data = np.delete(data, drop_data, axis=0)\n",
        "  label = np.delete(label, drop_data, axis=0)\n",
        "  return data, label"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jo2LLYeFFRuR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def sentiment_predict(sentence, okt, stopwords, tokenizer):\n",
        "  sentence = okt.morphs(sentence, stem=True)\n",
        "  sentence = [word for word in sentence if not word in stopwords]\n",
        "  encoded = tokenizer.texts_to_sequences([sentence])\n",
        "  padding_sentence = pad_sequences(encoded, maxlen = 30)\n",
        "  score = float(loaded_model.predict(padding_sentence))\n",
        "  if score > 0.5:\n",
        "    print(f\"긍정 / Score : {score}\")\n",
        "  else:\n",
        "    print(f\"부정 / Score : {score}\")\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rtIwqEy43obf",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 407
        },
        "outputId": "b0c4c52e-64b5-4fb3-f456-83ad725a73f9"
      },
      "source": [
        "# 데이터 tokenizing 하기\n",
        "train_data = pd.read_table('ratings_train.txt')\n",
        "test_data = pd.read_table('ratings_test.txt')\n",
        "X_train = list()\n",
        "X_test = list()\n",
        "okt = Okt()\n",
        "stopwords = ['의','가','이','은','들','는','좀','잘','걍','과','도','를','으로','자','에','와','한','하다']\n",
        "\n",
        "train_data = preprocessing(train_data)\n",
        "test_data = preprocessing(test_data)\n",
        "\n",
        "X_train = Token(train_data, okt, stopwords)\n",
        "X_test = Token(test_data, okt, stopwords)\n",
        "\n",
        "\n"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "start token\n",
            "token : 0/145791\n",
            "token : 10000/145791\n",
            "token : 20000/145791\n",
            "token : 30000/145791\n",
            "token : 40000/145791\n",
            "token : 50000/145791\n",
            "token : 60000/145791\n",
            "token : 70000/145791\n",
            "token : 80000/145791\n",
            "token : 90000/145791\n",
            "token : 100000/145791\n",
            "token : 110000/145791\n",
            "token : 120000/145791\n",
            "token : 130000/145791\n",
            "token : 140000/145791\n",
            "end token\n",
            "start token\n",
            "token : 0/48995\n",
            "token : 10000/48995\n",
            "token : 20000/48995\n",
            "token : 30000/48995\n",
            "token : 40000/48995\n",
            "end token\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "REFQFezQtOaB",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mO8Ke9T5wJ4d",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tokenizer = Tokenizer()\n",
        "tokenizer.fit_on_texts(X_train)\n",
        "\n",
        "X_train = Tokenizing(X_train, tokenizer)\n",
        "X_test = Tokenizing(X_test, tokenizer)"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bYnyO1tmE_pQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# label 데이터 생성\n",
        "Y_train = np.array(train_data['label'])\n",
        "Y_test = np.array(test_data['label'])\n",
        "\n",
        "X_train, Y_train = rmEmpty(X_train, Y_train)"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_9u6ag1FLdmS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# padding\n",
        "X_train = pad_sequences(X_train, maxlen = 100, padding='post')\n",
        "X_test = pad_sequences(X_test, maxlen = 100, padding='post')"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cYJCPxcIvqjc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "earlyStop = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=4)\n",
        "modelCP = ModelCheckpoint('best_model.h5', monitor='val_acc', mode='max', verbose=1, save_best_only=True)\n"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "mV4cBA1LXu9t",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 586
        },
        "outputId": "eb016510-efb9-4a40-e92d-76405c1cf189"
      },
      "source": [
        "embedding_dim = 256\n",
        "hidden_dim = 512\n",
        "dropout_rate = 0.6\n",
        "\n",
        "# Model\n",
        "input = Input(shape=(100,))\n",
        "x = Embedding(2542, embedding_dim)(input)\n",
        "x = Dropout(dropout_rate)(x)\n",
        "x = Conv1D(hidden_dim, 5, padding=\"same\")(x)\n",
        "x = BatchNormalization()(x)\n",
        "x = LeakyReLU()(x)\n",
        "x_res = x\n",
        "x = Bidirectional(LSTM(int(hidden_dim/2), return_sequences=True))(x)\n",
        "x= x+x_res\n",
        "x = LeakyReLU()(x)\n",
        "x = LSTM(hidden_dim, return_sequences=True)(x)\n",
        "x = GlobalMaxPool1D()(x)\n",
        "x = Dropout(dropout_rate)(x)\n",
        "output = Dense(1, activation='sigmoid')(x)\n",
        "\n",
        "model = Model(inputs = [input], outputs=output)\n",
        "\n",
        "optimizer = Adam(learning_rate=0.001)\n",
        "loss_function = BinaryCrossentropy()\n",
        "model.compile(optimizer=optimizer, loss=loss_function, metrics=['acc'])\n",
        "model.summary()"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"functional_1\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            [(None, 100)]        0                                            \n",
            "__________________________________________________________________________________________________\n",
            "embedding (Embedding)           (None, 100, 256)     650752      input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dropout (Dropout)               (None, 100, 256)     0           embedding[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv1d (Conv1D)                 (None, 100, 512)     655872      dropout[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization (BatchNorma (None, 100, 512)     2048        conv1d[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu (LeakyReLU)         (None, 100, 512)     0           batch_normalization[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "bidirectional (Bidirectional)   (None, 100, 512)     1574912     leaky_re_lu[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "tf_op_layer_AddV2 (TensorFlowOp [(None, 100, 512)]   0           bidirectional[0][0]              \n",
            "                                                                 leaky_re_lu[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_1 (LeakyReLU)       (None, 100, 512)     0           tf_op_layer_AddV2[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "lstm_1 (LSTM)                   (None, 100, 512)     2099200     leaky_re_lu_1[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "global_max_pooling1d (GlobalMax (None, 512)          0           lstm_1[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "dropout_1 (Dropout)             (None, 512)          0           global_max_pooling1d[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "dense (Dense)                   (None, 1)            513         dropout_1[0][0]                  \n",
            "==================================================================================================\n",
            "Total params: 4,983,297\n",
            "Trainable params: 4,982,273\n",
            "Non-trainable params: 1,024\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "POsODrusphk1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "czjmxFtlXxcO",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "365f34ec-03b5-4808-a384-65afeb5b8625"
      },
      "source": [
        "# history = model.fit(X_train, Y_train, epochs=100, callbacks=[earlyStop, modelCP], batch_size=128, validation_split=0.2)\n",
        "history = model.fit(X_train, Y_train, epochs=100, callbacks=[earlyStop, modelCP], batch_size=256, validation_split=0.2)"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "456/456 [==============================] - ETA: 0s - loss: 0.4907 - acc: 0.7487\n",
            "Epoch 00001: val_acc did not improve from 0.86337\n",
            "456/456 [==============================] - 78s 172ms/step - loss: 0.4907 - acc: 0.7487 - val_loss: 0.4146 - val_acc: 0.8098\n",
            "Epoch 2/100\n",
            "456/456 [==============================] - ETA: 0s - loss: 0.3920 - acc: 0.8199\n",
            "Epoch 00002: val_acc did not improve from 0.86337\n",
            "456/456 [==============================] - 77s 170ms/step - loss: 0.3920 - acc: 0.8199 - val_loss: 0.3741 - val_acc: 0.8303\n",
            "Epoch 3/100\n",
            "456/456 [==============================] - ETA: 0s - loss: 0.3638 - acc: 0.8349\n",
            "Epoch 00003: val_acc did not improve from 0.86337\n",
            "456/456 [==============================] - 78s 170ms/step - loss: 0.3638 - acc: 0.8349 - val_loss: 0.3548 - val_acc: 0.8432\n",
            "Epoch 4/100\n",
            "456/456 [==============================] - ETA: 0s - loss: 0.3461 - acc: 0.8446\n",
            "Epoch 00004: val_acc did not improve from 0.86337\n",
            "456/456 [==============================] - 78s 170ms/step - loss: 0.3461 - acc: 0.8446 - val_loss: 0.3454 - val_acc: 0.8459\n",
            "Epoch 5/100\n",
            "456/456 [==============================] - ETA: 0s - loss: 0.3297 - acc: 0.8545\n",
            "Epoch 00005: val_acc did not improve from 0.86337\n",
            "456/456 [==============================] - 78s 170ms/step - loss: 0.3297 - acc: 0.8545 - val_loss: 0.3411 - val_acc: 0.8491\n",
            "Epoch 6/100\n",
            "456/456 [==============================] - ETA: 0s - loss: 0.3169 - acc: 0.8606\n",
            "Epoch 00006: val_acc did not improve from 0.86337\n",
            "456/456 [==============================] - 78s 171ms/step - loss: 0.3169 - acc: 0.8606 - val_loss: 0.3416 - val_acc: 0.8526\n",
            "Epoch 7/100\n",
            "456/456 [==============================] - ETA: 0s - loss: 0.3071 - acc: 0.8655\n",
            "Epoch 00007: val_acc did not improve from 0.86337\n",
            "456/456 [==============================] - 78s 171ms/step - loss: 0.3071 - acc: 0.8655 - val_loss: 0.3393 - val_acc: 0.8552\n",
            "Epoch 8/100\n",
            "456/456 [==============================] - ETA: 0s - loss: 0.2960 - acc: 0.8721\n",
            "Epoch 00008: val_acc did not improve from 0.86337\n",
            "456/456 [==============================] - 78s 171ms/step - loss: 0.2960 - acc: 0.8721 - val_loss: 0.3385 - val_acc: 0.8591\n",
            "Epoch 9/100\n",
            "456/456 [==============================] - ETA: 0s - loss: 0.2847 - acc: 0.8768\n",
            "Epoch 00009: val_acc did not improve from 0.86337\n",
            "456/456 [==============================] - 78s 171ms/step - loss: 0.2847 - acc: 0.8768 - val_loss: 0.3372 - val_acc: 0.8602\n",
            "Epoch 10/100\n",
            "456/456 [==============================] - ETA: 0s - loss: 0.2785 - acc: 0.8803\n",
            "Epoch 00010: val_acc did not improve from 0.86337\n",
            "456/456 [==============================] - 78s 171ms/step - loss: 0.2785 - acc: 0.8803 - val_loss: 0.3427 - val_acc: 0.8607\n",
            "Epoch 11/100\n",
            "456/456 [==============================] - ETA: 0s - loss: 0.2701 - acc: 0.8841\n",
            "Epoch 00011: val_acc did not improve from 0.86337\n",
            "456/456 [==============================] - 78s 171ms/step - loss: 0.2701 - acc: 0.8841 - val_loss: 0.3444 - val_acc: 0.8601\n",
            "Epoch 12/100\n",
            "456/456 [==============================] - ETA: 0s - loss: 0.2612 - acc: 0.8886\n",
            "Epoch 00012: val_acc did not improve from 0.86337\n",
            "456/456 [==============================] - 78s 171ms/step - loss: 0.2612 - acc: 0.8886 - val_loss: 0.3402 - val_acc: 0.8621\n",
            "Epoch 13/100\n",
            "456/456 [==============================] - ETA: 0s - loss: 0.2549 - acc: 0.8919\n",
            "Epoch 00013: val_acc did not improve from 0.86337\n",
            "456/456 [==============================] - 78s 171ms/step - loss: 0.2549 - acc: 0.8919 - val_loss: 0.3364 - val_acc: 0.8625\n",
            "Epoch 14/100\n",
            "456/456 [==============================] - ETA: 0s - loss: 0.2480 - acc: 0.8962\n",
            "Epoch 00014: val_acc did not improve from 0.86337\n",
            "456/456 [==============================] - 78s 171ms/step - loss: 0.2480 - acc: 0.8962 - val_loss: 0.3442 - val_acc: 0.8618\n",
            "Epoch 15/100\n",
            "456/456 [==============================] - ETA: 0s - loss: 0.2423 - acc: 0.8980\n",
            "Epoch 00015: val_acc improved from 0.86337 to 0.86622, saving model to best_model.h5\n",
            "456/456 [==============================] - 78s 171ms/step - loss: 0.2423 - acc: 0.8980 - val_loss: 0.3500 - val_acc: 0.8662\n",
            "Epoch 16/100\n",
            "456/456 [==============================] - ETA: 0s - loss: 0.2332 - acc: 0.9022\n",
            "Epoch 00016: val_acc did not improve from 0.86622\n",
            "456/456 [==============================] - 78s 171ms/step - loss: 0.2332 - acc: 0.9022 - val_loss: 0.3502 - val_acc: 0.8645\n",
            "Epoch 17/100\n",
            "456/456 [==============================] - ETA: 0s - loss: 0.2267 - acc: 0.9061\n",
            "Epoch 00017: val_acc did not improve from 0.86622\n",
            "456/456 [==============================] - 78s 170ms/step - loss: 0.2267 - acc: 0.9061 - val_loss: 0.3547 - val_acc: 0.8632\n",
            "Epoch 00017: early stopping\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}