{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "MoodPiggyBankLikePytorch.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "oT-2KuRl3cyT",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 330
        },
        "outputId": "6cf24e20-70b9-48d3-f1af-f5366270c44c"
      },
      "source": [
        "!pip install konlpy\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "%matplotlib inline\n",
        "import matplotlib.pyplot as plt\n",
        "import re\n",
        "import urllib.request\n",
        "from konlpy.tag import Okt\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.optimizers import *\n",
        "from tensorflow.keras.losses import *\n",
        "from tensorflow.nn import *\n",
        "\n",
        "\n",
        "from tensorflow.keras.layers import *\n",
        "from tensorflow.keras.models import Sequential, Model\n",
        "from tensorflow.keras.models import load_model\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
        "\n",
        "urllib.request.urlretrieve(\"https://raw.githubusercontent.com/e9t/nsmc/master/ratings_train.txt\", filename=\"ratings_train.txt\")\n",
        "urllib.request.urlretrieve(\"https://raw.githubusercontent.com/e9t/nsmc/master/ratings_test.txt\", filename=\"ratings_test.txt\")\n",
        "\n"
      ],
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: konlpy in /usr/local/lib/python3.6/dist-packages (0.5.2)\n",
            "Requirement already satisfied: tweepy>=3.7.0 in /usr/local/lib/python3.6/dist-packages (from konlpy) (3.9.0)\n",
            "Requirement already satisfied: lxml>=4.1.0 in /usr/local/lib/python3.6/dist-packages (from konlpy) (4.2.6)\n",
            "Requirement already satisfied: colorama in /usr/local/lib/python3.6/dist-packages (from konlpy) (0.4.3)\n",
            "Requirement already satisfied: JPype1>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from konlpy) (1.0.2)\n",
            "Requirement already satisfied: numpy>=1.6 in /usr/local/lib/python3.6/dist-packages (from konlpy) (1.18.5)\n",
            "Requirement already satisfied: beautifulsoup4==4.6.0 in /usr/local/lib/python3.6/dist-packages (from konlpy) (4.6.0)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from tweepy>=3.7.0->konlpy) (1.15.0)\n",
            "Requirement already satisfied: requests[socks]>=2.11.1 in /usr/local/lib/python3.6/dist-packages (from tweepy>=3.7.0->konlpy) (2.23.0)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from tweepy>=3.7.0->konlpy) (1.3.0)\n",
            "Requirement already satisfied: typing-extensions; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from JPype1>=0.7.0->konlpy) (3.7.4.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests[socks]>=2.11.1->tweepy>=3.7.0->konlpy) (2020.6.20)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests[socks]>=2.11.1->tweepy>=3.7.0->konlpy) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests[socks]>=2.11.1->tweepy>=3.7.0->konlpy) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests[socks]>=2.11.1->tweepy>=3.7.0->konlpy) (2.10)\n",
            "Requirement already satisfied: PySocks!=1.5.7,>=1.5.6; extra == \"socks\" in /usr/local/lib/python3.6/dist-packages (from requests[socks]>=2.11.1->tweepy>=3.7.0->konlpy) (1.7.1)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.6/dist-packages (from requests-oauthlib>=0.7.0->tweepy>=3.7.0->konlpy) (3.1.0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('ratings_test.txt', <http.client.HTTPMessage at 0x7fa1e43cf0b8>)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 62
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5-hhpAxOYzMr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def preprocessing(data):\n",
        "  data = data.drop_duplicates(subset=['document'])\n",
        "  data = data.dropna(how = 'any')\n",
        "  data['document'] = data['document'].str.replace(\"[^ㄱ-ㅎㅏ-ㅣ가-힣 ]\",\"\")\n",
        "  data['document'] = data['document'].replace('', np.nan)\n",
        "  data = data.dropna(how = 'any')\n",
        "  return data"
      ],
      "execution_count": 63,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AB4FFTBA4U9G",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def Token(data, okt, stopwords):\n",
        "  now = 0\n",
        "  res = list()\n",
        "  print(\"start token\")\n",
        "  for sentence in data['document']:\n",
        "    if now%10000 == 0:\n",
        "      print(f\"token : {now}/{len(data)}\")\n",
        "    now = now +1\n",
        "    temp = list()\n",
        "    temp = okt.morphs(sentence, stem=True)\n",
        "    temp = [word for word in temp if not word in stopwords]\n",
        "    res.append(temp)\n",
        "  print(\"end token\")\n",
        "  return res"
      ],
      "execution_count": 64,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-58IuB2LTZRI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def Tokenizing(data, tokenizer):\n",
        "  return tokenizer.texts_to_sequences(data)"
      ],
      "execution_count": 65,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "akEbJd15nU-l",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def rmEmpty(data, label):\n",
        "  drop_data = [index for index, sentence in enumerate(X_train) if len(sentence) < 1]\n",
        "  data = np.delete(data, drop_data, axis=0)\n",
        "  label = np.delete(label, drop_data, axis=0)\n",
        "  return data, label"
      ],
      "execution_count": 66,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jo2LLYeFFRuR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def sentiment_predict(sentence, okt, stopwords, tokenizer):\n",
        "  sentence = okt.morphs(sentence, stem=True)\n",
        "  sentence = [word for word in sentence if not word in stopwords]\n",
        "  encoded = tokenizer.texts_to_sequences([sentence])\n",
        "  padding_sentence = pad_sequences(encoded, maxlen = 30)\n",
        "  score = float(loaded_model.predict(padding_sentence))\n",
        "  if score > 0.5:\n",
        "    print(f\"긍정 / Score : {score}\")\n",
        "  else:\n",
        "    print(f\"부정 / Score : {score}\")\n"
      ],
      "execution_count": 67,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rtIwqEy43obf",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 407
        },
        "outputId": "e1635a9c-40b1-42b8-eec6-0d855f84c119"
      },
      "source": [
        "# 데이터 tokenizing 하기\n",
        "train_data = pd.read_table('ratings_train.txt')\n",
        "test_data = pd.read_table('ratings_test.txt')\n",
        "X_train = list()\n",
        "X_test = list()\n",
        "okt = Okt()\n",
        "stopwords = ['의','가','이','은','들','는','좀','잘','걍','과','도','를','으로','자','에','와','한','하다']\n",
        "\n",
        "train_data = preprocessing(train_data)\n",
        "test_data = preprocessing(test_data)\n",
        "\n",
        "X_train = Token(train_data, okt, stopwords)\n",
        "X_test = Token(test_data, okt, stopwords)\n",
        "\n",
        "tokenizer = Tokenizer(19417, oov_token = 'OOV')\n",
        "tokenizer.fit_on_texts(X_train)\n",
        "\n",
        "X_train = Tokenizing(X_train, tokenizer)\n",
        "X_test = Tokenizing(X_test, tokenizer)\n"
      ],
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "start token\n",
            "token : 0/145791\n",
            "token : 10000/145791\n",
            "token : 20000/145791\n",
            "token : 30000/145791\n",
            "token : 40000/145791\n",
            "token : 50000/145791\n",
            "token : 60000/145791\n",
            "token : 70000/145791\n",
            "token : 80000/145791\n",
            "token : 90000/145791\n",
            "token : 100000/145791\n",
            "token : 110000/145791\n",
            "token : 120000/145791\n",
            "token : 130000/145791\n",
            "token : 140000/145791\n",
            "end token\n",
            "start token\n",
            "token : 0/48995\n",
            "token : 10000/48995\n",
            "token : 20000/48995\n",
            "token : 30000/48995\n",
            "token : 40000/48995\n",
            "end token\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pIMoitOm4Bmt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# label 데이터 생성\n",
        "Y_train = np.array(train_data['label'])\n",
        "Y_test = np.array(test_data['label'])\n",
        "\n",
        "X_train, Y_train = rmEmpty(X_train, Y_train)\n",
        "\n",
        "# padding\n",
        "X_train = pad_sequences(X_train, maxlen = 30, padding='post')\n",
        "X_test = pad_sequences(X_test, maxlen = 30, padding='post')"
      ],
      "execution_count": 69,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2mHRiaF3Uagh",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        },
        "outputId": "5276d561-6010-482d-a617-1d05a16a821e"
      },
      "source": [
        "print(len(X_train))"
      ],
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "145380\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cYJCPxcIvqjc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "earlyStop = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=4)\n",
        "modelCP = ModelCheckpoint('best_model.h5', monitor='val_acc', mode='max', verbose=1, save_best_only=True)\n"
      ],
      "execution_count": 71,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RZTJ38zvWUeA",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 375
        },
        "outputId": "119d07d3-ef43-4d1b-f579-a6633f4e8732"
      },
      "source": [
        "# Model\n",
        "input = Input(shape=(30,))\n",
        "x = Embedding(19417, 128)(input)\n",
        "x = LeakyReLU()(x)\n",
        "x = Dropout(0.5)(x)\n",
        "x = Bidirectional(LSTM(32, return_sequences=True))(x)\n",
        "x = LeakyReLU()(x)\n",
        "output = Dense(1, activation='sigmoid')(x)\n",
        "\n",
        "model = Model(inputs = [input], outputs=output)\n",
        "\n",
        "optimizer = Adam(learning_rate=0.0001)\n",
        "loss_function = BinaryCrossentropy()\n",
        "model.compile(optimizer=optimizer, loss=loss_function, metrics=['acc'])\n",
        "model.summary()"
      ],
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"functional_53\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_31 (InputLayer)        [(None, 30)]              0         \n",
            "_________________________________________________________________\n",
            "embedding_30 (Embedding)     (None, 30, 128)           2485376   \n",
            "_________________________________________________________________\n",
            "leaky_re_lu_27 (LeakyReLU)   (None, 30, 128)           0         \n",
            "_________________________________________________________________\n",
            "dropout_31 (Dropout)         (None, 30, 128)           0         \n",
            "_________________________________________________________________\n",
            "bidirectional_7 (Bidirection (None, 30, 64)            41216     \n",
            "_________________________________________________________________\n",
            "leaky_re_lu_28 (LeakyReLU)   (None, 30, 64)            0         \n",
            "_________________________________________________________________\n",
            "dense_27 (Dense)             (None, 30, 1)             65        \n",
            "=================================================================\n",
            "Total params: 2,526,657\n",
            "Trainable params: 2,526,657\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xJOsE28fw6gY",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 748
        },
        "outputId": "f614c797-f3f2-4ade-c0c3-9a718c8625d0"
      },
      "source": [
        "history = model.fit(X_train, Y_train, epochs=15, callbacks=[earlyStop, modelCP], batch_size=128, validation_split=0.2)"
      ],
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/15\n",
            "908/909 [============================>.] - ETA: 0s - loss: 0.5847 - acc: 0.7035\n",
            "Epoch 00001: val_acc improved from -inf to 0.81383, saving model to best_model.h5\n",
            "909/909 [==============================] - 29s 32ms/step - loss: 0.5846 - acc: 0.7036 - val_loss: 0.4670 - val_acc: 0.8138\n",
            "Epoch 2/15\n",
            "908/909 [============================>.] - ETA: 0s - loss: 0.4233 - acc: 0.8200\n",
            "Epoch 00002: val_acc improved from 0.81383 to 0.83337, saving model to best_model.h5\n",
            "909/909 [==============================] - 29s 31ms/step - loss: 0.4232 - acc: 0.8200 - val_loss: 0.3944 - val_acc: 0.8334\n",
            "Epoch 3/15\n",
            "909/909 [==============================] - ETA: 0s - loss: 0.3744 - acc: 0.8402\n",
            "Epoch 00003: val_acc improved from 0.83337 to 0.83809, saving model to best_model.h5\n",
            "909/909 [==============================] - 28s 31ms/step - loss: 0.3744 - acc: 0.8402 - val_loss: 0.3766 - val_acc: 0.8381\n",
            "Epoch 4/15\n",
            "909/909 [==============================] - ETA: 0s - loss: 0.3521 - acc: 0.8504\n",
            "Epoch 00004: val_acc improved from 0.83809 to 0.84154, saving model to best_model.h5\n",
            "909/909 [==============================] - 28s 31ms/step - loss: 0.3521 - acc: 0.8504 - val_loss: 0.3669 - val_acc: 0.8415\n",
            "Epoch 5/15\n",
            "909/909 [==============================] - ETA: 0s - loss: 0.3376 - acc: 0.8581\n",
            "Epoch 00005: val_acc improved from 0.84154 to 0.84248, saving model to best_model.h5\n",
            "909/909 [==============================] - 28s 31ms/step - loss: 0.3376 - acc: 0.8581 - val_loss: 0.3637 - val_acc: 0.8425\n",
            "Epoch 6/15\n",
            "909/909 [==============================] - ETA: 0s - loss: 0.3277 - acc: 0.8618\n",
            "Epoch 00006: val_acc improved from 0.84248 to 0.84260, saving model to best_model.h5\n",
            "909/909 [==============================] - 28s 31ms/step - loss: 0.3277 - acc: 0.8618 - val_loss: 0.3629 - val_acc: 0.8426\n",
            "Epoch 7/15\n",
            "909/909 [==============================] - ETA: 0s - loss: 0.3179 - acc: 0.8678\n",
            "Epoch 00007: val_acc improved from 0.84260 to 0.84351, saving model to best_model.h5\n",
            "909/909 [==============================] - 28s 30ms/step - loss: 0.3179 - acc: 0.8678 - val_loss: 0.3613 - val_acc: 0.8435\n",
            "Epoch 8/15\n",
            "909/909 [==============================] - ETA: 0s - loss: 0.3117 - acc: 0.8699\n",
            "Epoch 00008: val_acc improved from 0.84351 to 0.84362, saving model to best_model.h5\n",
            "909/909 [==============================] - 28s 30ms/step - loss: 0.3117 - acc: 0.8699 - val_loss: 0.3645 - val_acc: 0.8436\n",
            "Epoch 9/15\n",
            "909/909 [==============================] - ETA: 0s - loss: 0.3065 - acc: 0.8723\n",
            "Epoch 00009: val_acc did not improve from 0.84362\n",
            "909/909 [==============================] - 28s 30ms/step - loss: 0.3065 - acc: 0.8723 - val_loss: 0.3644 - val_acc: 0.8421\n",
            "Epoch 10/15\n",
            "909/909 [==============================] - ETA: 0s - loss: 0.3018 - acc: 0.8749\n",
            "Epoch 00010: val_acc did not improve from 0.84362\n",
            "909/909 [==============================] - 28s 30ms/step - loss: 0.3018 - acc: 0.8749 - val_loss: 0.3699 - val_acc: 0.8424\n",
            "Epoch 11/15\n",
            "909/909 [==============================] - ETA: 0s - loss: 0.2970 - acc: 0.8772\n",
            "Epoch 00011: val_acc did not improve from 0.84362\n",
            "909/909 [==============================] - 27s 30ms/step - loss: 0.2970 - acc: 0.8772 - val_loss: 0.3676 - val_acc: 0.8427\n",
            "Epoch 00011: early stopping\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aTIGFbSOnua3",
        "colab_type": "text"
      },
      "source": [
        "Embedding 128, LSTM 128, Dense 1 sigmoid   \n",
        "Score : 0.8499\n",
        "\n",
        "Embedding 128, LSTM 128, Dense 1 sigmoid, dropout 0.5\n",
        "Score : 0.8505\n",
        "\n",
        "Embedding 128, LSTM 128, Dense 1 sigmoid, dropout 0.5, resnet dropout 0.5\n",
        "Score : 0.8531\n",
        "\n",
        "0.8451\n",
        "\n",
        "padding post "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2d2P2lKuxR2H",
        "colab_type": "text"
      },
      "source": [
        "# Model\n",
        "Embedding 100, LSTM 128, Dense 1 sigmoid, batch_size = 60\n",
        "val_acc : 0.8605\n",
        "\n",
        "Embedding 256, LSTM 256, Dense 1 sigmoid, batch_size = 60\n",
        "val_acc : 0.8591\n",
        "\n",
        "Embedding 256, LSTM 256, Dense 1 sigmoid, batch_size = 128\n",
        "val_acc : 0.8550\n",
        "\n",
        "Embedding 256, LSTM 256, Dense 1 sigmoid, batch_size = 128, adam\n",
        "val_acc : 0.8481\n",
        "\n",
        "Embedding 256, LSTM 256, Dense 1 sigmoid, batch_size = 128, adam, dropout 0.2\n",
        "val_acc : 0.8510\n",
        "\n",
        "Embedding 256, LSTM 256, Dense 1 sigmoid, batch_size = 128, adam, dropout 0.5\n",
        "val_acc : 0.8490\n",
        "\n",
        "Embedding 256, LSTM 256, Dense 1 sigmoid, batch_size = 128, adam, dropout 0.5\n",
        "val_acc : 0.8525\n",
        "\n",
        "Embedding 256, GRU 256, Dense 1 sigmoid, batch_size = 128, adam, dropout 0.5\n",
        "val_acc : 0.8537\n",
        "\n",
        "Embedding 256, GRU 256, Dense 1 sigmoid, batch_size = 128, adam, change dropout 0.5\n",
        "val_acc : 0.8552\n",
        "\n",
        "Embedding 256, GRU 256, Dense 1 sigmoid, batch_size = 128, adam, change dropout 0.5, amsgrad\n",
        "val_acc : 0.8556"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HaxmoRwLAg3m",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        },
        "outputId": "7a08ce3c-165f-4380-822c-3d254efe1d42"
      },
      "source": [
        "loaded_model = load_model('best_model.h5')\n",
        "\n",
        "sentiment_predict(\"이 영화 재미없어요...\", okt, stopwords, tokenizer)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "부정 / Score : 0.028914857655763626\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sQA_hoNjG3E6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}